# ãƒ­ãƒ¼ã‚«ãƒ«LLMæŠ€è¡“èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆ

èª¿æŸ»æ—¥: 2024-12-23
æœ€çµ‚æ›´æ–°: 2026-01-04

---

## âš ï¸ é‡è¦ãªæ›´æ–° (2026-01-04)

**Gemma 3n E2Bã¯react-native-executorchã§ç›´æ¥ä½¿ç”¨ã§ããªã„ã“ã¨ãŒåˆ¤æ˜**

| å•é¡Œç‚¹ | è©³ç´° |
|--------|------|
| **ãƒ¢ãƒ‡ãƒ«å½¢å¼** | Gemma 3nã¯`.task`å½¢å¼ï¼ˆGoogle AI Edge SDKï¼‰ã§æä¾› |
| **å¿…è¦å½¢å¼** | react-native-executorchã¯`.pte`å½¢å¼ãŒå¿…è¦ |
| **å¤‰æ›èª²é¡Œ** | ExecuTorchå½¢å¼ã¸ã®å¤‰æ›ã«æŠ€è¡“çš„å•é¡Œã‚ã‚Š ([Issue #16411](https://github.com/pytorch/executorch/issues/16411)) |

### ä¿®æ­£å¾Œã®æ¨å¥¨

| å„ªå…ˆåº¦ | ãƒ¢ãƒ‡ãƒ« | ç†ç”± |
|--------|--------|------|
| **1ä½** | Llama 3.2 1B | react-native-executorchã§å…¬å¼.pteãƒ•ã‚¡ã‚¤ãƒ«æä¾› |
| **2ä½** | Qwen 3 | 119è¨€èªå¯¾å¿œï¼ˆæ—¥æœ¬èªå«ã‚€ï¼‰ã€ExecuTorchå¯¾å¿œ |
| **3ä½** | Gemma 3n GGUF + llama.rn | æ—¥æœ¬èªå„ªç§€ã ãŒåˆ¥ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ |

**è©³ç´°ãªå®Ÿè£…è¨ˆç”»**: [llm-integration-plan.md](./llm-integration-plan.md)

---

## ğŸ¯ æ¡ç”¨æ±ºå®š (æ”¹è¨‚)

| é …ç›® | æ±ºå®šå†…å®¹ |
|------|---------|
| **æ¡ç”¨ãƒ¢ãƒ‡ãƒ«** | **Llama 3.2 1B** (Phase 1) â†’ Qwen 3 (Phase 2æ¤œè¨) |
| **çµ±åˆæ–¹æ³•** | react-native-executorch |
| **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰** | ã‚ªãƒ³ãƒœãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¾Œã€ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ |
| **æ±ºå®šæ—¥** | 2026å¹´1æœˆ4æ—¥ï¼ˆæ”¹è¨‚ï¼‰ |

### é¸å®šç†ç”±
1. **å…¬å¼ã‚µãƒãƒ¼ãƒˆ** â†’ react-native-executorchã§.pteãƒ•ã‚¡ã‚¤ãƒ«æä¾›æ¸ˆã¿
2. **Expo SDK 54äº’æ›** â†’ StopShortsã®ç¾ç’°å¢ƒã¨å®Œå…¨äº’æ›
3. **è»½é‡** â†’ 500MBç¨‹åº¦ã€2GB RAMã§å‹•ä½œå¯èƒ½
4. **æ—¥æœ¬èª** â†’ é™å®šçš„ã ãŒã€å¿…è¦ã«å¿œã˜ã¦Qwen 3ã¸ç§»è¡Œå¯èƒ½

---

## ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

| ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  | å¯¾å¿œçŠ¶æ³ | æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ | å¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ç‡ |
|-----------------|---------|---------------|---------------|
| **iOS** | âœ… å¯¾å¿œå¯èƒ½ | react-native-executorch + Llama 3.2 | RAM â‰¥ 2GB ã®ãƒ‡ãƒã‚¤ã‚¹ |
| **Android** | âœ… å¯¾å¿œå¯èƒ½ | react-native-executorch + Llama 3.2 | RAM â‰¥ 2GB ã®ãƒ‡ãƒã‚¤ã‚¹ |
| **React Native** | âœ… æ¡ç”¨æ±ºå®š | react-native-executorch | - |

**çµè«–**: Llama 3.2 1Bã§å®Ÿè£…é–‹å§‹ã€‚æ—¥æœ¬èªå“è³ªãŒä¸ååˆ†ãªå ´åˆã¯Qwen 3ã¸ç§»è¡Œã€‚

---

## 1. iOS ãƒ­ãƒ¼ã‚«ãƒ«LLM

### 1.1 Apple Intelligence (æ¨å¥¨)

**æ¦‚è¦**: iOS 18.1+ ã§åˆ©ç”¨å¯èƒ½ãªå…¬å¼APIã§ã€Appleã®ç´„30å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨

**ãƒ¡ãƒªãƒƒãƒˆ**:
- AppleãŒæœ€é©åŒ–æ¸ˆã¿ï¼ˆé«˜é€Ÿãƒ»çœé›»åŠ›ï¼‰
- APIå‘¼ã³å‡ºã—ãŒç„¡æ–™ï¼ˆã‚µãƒ¼ãƒãƒ¼ã‚³ã‚¹ãƒˆä¸è¦ï¼‰
- ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§å‹•ä½œ
- ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒãƒ‡ãƒã‚¤ã‚¹å¤–ã«å‡ºãªã„ï¼‰
- 3è¡Œã®Swiftã‚³ãƒ¼ãƒ‰ã§çµ±åˆå¯èƒ½

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- **å¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ãŒé™å®šçš„**ï¼ˆä¸‹è¨˜å‚ç…§ï¼‰
- 8GB RAM + A17 Proä»¥é™ãŒå¿…é ˆ
- ä¸­å›½æœ¬åœŸã§ã¯åˆ©ç”¨ä¸å¯

**å¯¾å¿œãƒ‡ãƒã‚¤ã‚¹**:
| ãƒ‡ãƒã‚¤ã‚¹ | ãƒãƒƒãƒ— | RAM |
|---------|--------|-----|
| iPhone 15 Pro / Pro Max | A17 Pro | 8GB |
| iPhone 16 / 16 Plus | A18 | 8GB |
| iPhone 16 Pro / Pro Max | A18 Pro | 8GB |
| iPad mini (A17 Pro) | A17 Pro | 8GB |
| iPad (M1ä»¥é™) | M1+ | 8GB+ |

**Foundation Models Framework** (iOS 26 / 2025å¹´ç§‹):
- ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£é–‹ç™ºè€…ãŒAppleã®ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹LLMã«ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
- ç¾æ™‚ç‚¹ã§ã¯ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆAPIã§åˆ©ç”¨ä¸å¯

### 1.2 Core ML + llama.cpp

**æ¦‚è¦**: ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¢ãƒ‡ãƒ«ï¼ˆLlama 3.1ãªã©ï¼‰ã‚’Core MLã§æœ€é©åŒ–ã—ã¦å®Ÿè¡Œ

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**:
- Llama-3.1-8B-Instruct on M1 Max: ç´„33 tokens/ç§’
- Int4é‡å­åŒ–ã§ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’å¤§å¹…å‰Šæ¸›

**ãƒ¡ãƒªãƒƒãƒˆ**:
- ãƒ¢ãƒ‡ãƒ«ã®è‡ªç”±ãªé¸æŠãŒå¯èƒ½
- ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¯èƒ½

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- æœ€é©åŒ–ä½œæ¥­ãŒå¿…è¦
- ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«ã‚ˆã£ã¦ã¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’æ¶ˆè²»ï¼ˆæ•°GBï¼‰
- å¤ã„ãƒ‡ãƒã‚¤ã‚¹ã§ã¯å®Ÿç”¨çš„ãªé€Ÿåº¦ãŒå‡ºãªã„

---

## 2. Android ãƒ­ãƒ¼ã‚«ãƒ«LLM

### 2.1 Gemini Nano (ML Kit GenAI API) (æ¨å¥¨)

**æ¦‚è¦**: Googleã®AICore ã‚·ã‚¹ãƒ†ãƒ ã‚µãƒ¼ãƒ“ã‚¹ä¸Šã§å‹•ä½œã™ã‚‹1.8Bã€œ3.25Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«

**ãƒ¡ãƒªãƒƒãƒˆ**:
- GoogleãŒæœ€é©åŒ–æ¸ˆã¿
- å…±æœ‰ãƒ¢ãƒ‡ãƒ«ï¼ˆå„ã‚¢ãƒ—ãƒªãŒå€‹åˆ¥ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸è¦ï¼‰
- ç„¡æ–™ã§æ¨è«–å¯èƒ½
- ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‹•ä½œ

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- **å¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ãŒéå¸¸ã«é™å®šçš„**
- ãƒ•ã‚©ã‚¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®ã¿å‹•ä½œï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ä¸å¯ï¼‰
- æ¨è«–ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã‚ã‚Š

**å¯¾å¿œãƒ‡ãƒã‚¤ã‚¹** (2024å¹´12æœˆæ™‚ç‚¹):

| ãƒ¡ãƒ¼ã‚«ãƒ¼ | ãƒ¢ãƒ‡ãƒ« |
|---------|--------|
| Google | Pixel 8, 8 Pro, 8a, 9, 9 Pro, 9 Pro XL, 9 Pro Fold, 10ã‚·ãƒªãƒ¼ã‚º |
| Samsung | Galaxy S24, S24+, S24 Ultra, S24 FE, Z Flip 6, Z Fold 6, S25ã‚·ãƒªãƒ¼ã‚º |
| Xiaomi | 14T, 15ã‚·ãƒªãƒ¼ã‚º |
| ãã®ä»– | ä¸€éƒ¨ã®Motorola, Realme, OnePlus, Honorã®ãƒ•ãƒ©ãƒƒã‚°ã‚·ãƒƒãƒ— |

**Gemini Nano ãƒãƒ¼ã‚¸ãƒ§ãƒ³**:
- v1 (ãƒ†ã‚­ã‚¹ãƒˆã®ã¿): ç´„15ãƒ‡ãƒã‚¤ã‚¹å¯¾å¿œ
- v2 (ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«): Pixel 9ã‚·ãƒªãƒ¼ã‚ºä»¥é™ã®ã¿

### 2.2 llama.cpp (Androidç‰ˆ)

**æ¦‚è¦**: Qualcomm Adrenoãªã©ã®GPUã‚’ä½¿ç”¨ã—ãŸãƒ­ãƒ¼ã‚«ãƒ«æ¨è«–

**å¯¾å¿œGPU**: Adreno 700ã‚·ãƒªãƒ¼ã‚ºä»¥é™ï¼ˆãƒ†ã‚¹ãƒˆæ¸ˆã¿ï¼‰

**ãƒ¡ãƒªãƒƒãƒˆ**:
- ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒã‚¤ã‚¹ã§å‹•ä½œå¯èƒ½
- ãƒ¢ãƒ‡ãƒ«ã®è‡ªç”±é¸æŠ

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- ãƒ‡ãƒã‚¤ã‚¹ã”ã¨ã®æœ€é©åŒ–ãŒå¿…è¦
- ä¸€éƒ¨ãƒ‡ãƒã‚¤ã‚¹ã§ã¯é€Ÿåº¦ãŒä¸ååˆ†

---

## 3. React Native çµ±åˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª

### 3.1 llama.rn (æ¨å¥¨)

**ãƒªãƒã‚¸ãƒˆãƒª**: [mybigday/llama.rn](https://github.com/mybigday/llama.rn)

**æ¦‚è¦**: llama.cpp ã® React Native ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°

**è¦ä»¶**:
- React Native New Architecture å¿…é ˆ (v0.10ä»¥é™)
- iOS: Xcode 15+
- Android: NDK 27+

**æ©Ÿèƒ½**:
- GGUFå½¢å¼ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆ
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†

**æ¡ç”¨äº‹ä¾‹**:
- ChatterUI
- PocketPal AI

**ã‚³ãƒ¼ãƒ‰ä¾‹**:
```typescript
import { initLlama, LlamaContext } from 'llama.rn';

const context = await initLlama({
  model: 'path/to/model.gguf',
  n_ctx: 2048,
});

const result = await context.completion({
  prompt: 'Hello, ',
  n_predict: 100,
});
```

### 3.2 react-native-executorch

**ãƒªãƒã‚¸ãƒˆãƒª**: [software-mansion/react-native-executorch](https://github.com/software-mansion/react-native-executorch)

**æ¦‚è¦**: Meta ã® ExecuTorch ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ React Native ã§ä½¿ç”¨

**æ©Ÿèƒ½**:
- LLM (Llama 3.2ãªã©)
- éŸ³å£°èªè­˜ (Whisper)
- ç”»åƒåˆ†é¡ã€ç‰©ä½“æ¤œå‡º
- OCR

**Expoå¯¾å¿œ**: ã‚ã‚Šï¼ˆExpoãƒ–ãƒ­ã‚°ã§å…¬å¼ã‚¬ã‚¤ãƒ‰ã‚ã‚Šï¼‰

**ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—** (2025å¹´):
- ã‚ˆã‚Šå¤šãã®LLMå¯¾å¿œ (SmolLM2ãªã©)
- VLMå¯¾å¿œ (Moondream)
- åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«

### 3.3 Apple Intelligence for React Native (å°†æ¥)

**çŠ¶æ³**: [Callstack ãŒé–‹ç™ºä¸­](https://www.callstack.com/blog/on-device-apple-llm-support-comes-to-react-native)

**è¦ä»¶**:
- React Native 0.80+ ã¾ãŸã¯ Expo Canary
- New Architecture å¿…é ˆ
- iOS 26+ (2025å¹´ç§‹)

---

## 4. ãƒ¢ãƒ‡ãƒ«é¸æŠ

### 4.1 æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º

| ã‚µã‚¤ã‚º | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | RAMè¦ä»¶ | æ¨è«–é€Ÿåº¦ | å“è³ª |
|-------|-----------|---------|---------|------|
| å° | 1-2B | 2-4GB | é«˜é€Ÿ | åŸºæœ¬çš„ãªã‚¿ã‚¹ã‚¯ |
| ä¸­ | 3-4B | 4-6GB | ä¸­ç¨‹åº¦ | ä¼šè©±ã«é©åˆ‡ |
| å¤§ | 7-8B | 8GB+ | é…ã‚ | é«˜å“è³ª |

**StopShortså‘ã‘æ¨å¥¨**: 1-3Bãƒ¢ãƒ‡ãƒ«ï¼ˆä¼šè©±ã®è³ªã¨é€Ÿåº¦ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰

### 4.2 é‡å­åŒ–

- **Q4_K_M**: å“è³ªã¨ã‚µã‚¤ã‚ºã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„
- **Q5_0**: è‹¥å¹²é«˜å“è³ªã ãŒã‚µã‚¤ã‚ºå¢—
- **Q2**: æœ€å°ã‚µã‚¤ã‚ºã ãŒå“è³ªä½ä¸‹

### 4.3 2025-2026å¹´ æœ€æ–°è»½é‡ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼ˆ2026å¹´1æœˆæ›´æ–°ï¼‰

| ãƒ¢ãƒ‡ãƒ« | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | æ—¥æœ¬èªå¯¾å¿œ | RAMè¦ä»¶ | æ¨è«–é€Ÿåº¦ | ç‰¹å¾´ |
|--------|-----------|-----------|---------|---------|------|
| **Gemma 3n E2B** | 5B (å®ŸåŠ¹2B) | âœ… è‰¯å¥½ | 2GB | éå¸¸ã«é«˜é€Ÿ | 2GB RAMã§å‹•ä½œå¯èƒ½ã€ãƒ¢ãƒã‚¤ãƒ«æœ€é©åŒ– |
| **Gemma 3n E4B** | 8B (å®ŸåŠ¹4B) | âœ… è‰¯å¥½ | 3GB | é«˜é€Ÿ | LMArena 1300è¶…ãˆã€GPT-4.1-nanoç´š |
| **Gemma 2 2B JPN** | 2.6B | âœ… å°‚ç”¨ç‰ˆ | 3-4GB | é«˜é€Ÿ | æ—¥æœ¬èªç‰¹åŒ–ã€GPT-3.5ç´šã®æ€§èƒ½ |
| **Llama 3.2 1B** | 1B | âš ï¸ 8è¨€èª | 1-2GB | éå¸¸ã«é«˜é€Ÿ | é‡å­åŒ–ç‰ˆã§4å€é€Ÿã€56%ã‚µã‚¤ã‚ºå‰Šæ¸› |
| **Llama 3.2 3B** | 3B | âš ï¸ 8è¨€èª | 3-4GB | é«˜é€Ÿ | 19.92 tokens/ç§’ï¼ˆArmæœ€é©åŒ–ï¼‰ |
| **SmolLM3 3B** | 3B | âŒ æ¬§å·6è¨€èª | 4-5GB | é«˜é€Ÿ | Llama 3.2 3Bã‚’ä¸Šå›ã‚‹æ€§èƒ½ã€128Kå¯¾å¿œ |
| **Qwen 2.5 3B** | 3B | âœ… è‰¯å¥½ | 4-6GB | ä¸­ç¨‹åº¦ | 119è¨€èªå¯¾å¿œã€ãƒ¢ãƒã‚¤ãƒ«å‘ã‘è¨­è¨ˆ |
| **Phi-3 Mini** | 3.8B | âš ï¸ é™å®šçš„ | 2.4GB (é‡å­åŒ–) | é«˜é€Ÿ | 6-9Bãƒ¢ãƒ‡ãƒ«ç´šã®ç²¾åº¦ |

#### æ—¥æœ¬èªå¯¾å¿œè©•ä¾¡

**æœ€å„ªç§€ï¼ˆæ—¥æœ¬èªãƒã‚¤ãƒ†ã‚£ãƒ–ç´šï¼‰:**
- **Gemma 2 2B JPN**: Googleå…¬å¼ã®æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç‰ˆã€‚GPT-3.5ã¨åŒç­‰ã®æ—¥æœ¬èªæ€§èƒ½ã€‚
- **Gemma 3n**: å¤šè¨€èªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆWMT24++ï¼‰ã§æ—¥æœ¬èªå«ã‚€5è¨€èªã§é«˜è©•ä¾¡ã€‚

**å„ªç§€ï¼ˆå®Ÿç”¨ãƒ¬ãƒ™ãƒ«ï¼‰:**
- **Qwen 2.5 3B**: 119è¨€èªå¯¾å¿œã€‚æ—¥æœ¬èªãƒ»ä¸­å›½èªãƒ»éŸ“å›½èªãªã©æ±ã‚¢ã‚¸ã‚¢è¨€èªã«å¼·ã„ã€‚

**æ³¨æ„ãŒå¿…è¦:**
- **Llama 3.2**: å…¬å¼å¯¾å¿œã¯è‹±èªã€ãƒ‰ã‚¤ãƒ„èªã€ãƒ•ãƒ©ãƒ³ã‚¹èªãªã©8è¨€èªã€‚æ—¥æœ¬èªã¯éå…¬å¼ã€‚
- **SmolLM3**: æ¬§å·6è¨€èªã®ã¿ã€‚æ—¥æœ¬èªã¯éå¯¾å¿œã€‚
- **Phi-3**: å¤šè¨€èªå¯¾å¿œã ãŒæ—¥æœ¬èªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯é™å®šçš„ã€‚

#### ãƒ¢ãƒã‚¤ãƒ«æ¨è«–é€Ÿåº¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

| ãƒ¢ãƒ‡ãƒ« | ãƒ‡ãƒã‚¤ã‚¹ | é€Ÿåº¦ (tokens/ç§’) | å‚™è€ƒ |
|--------|---------|-----------------|------|
| Gemma 3n E4B | ãƒ¢ãƒã‚¤ãƒ«æœ€æ–° | 60-70 | Time-to-first-token: 0.3ç§’ |
| Llama 3.2 3B (é‡å­åŒ–) | Samsung S24+ | ~20 | Armæœ€é©åŒ–ã§3å€é€Ÿ |
| Llama 3.2 1B (é‡å­åŒ–) | Samsung S24+ | ~40 | æœ€è»½é‡ã§é«˜é€Ÿ |

---

## 5. StopShortså‘ã‘æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ï¼ˆ2026å¹´1æœˆæ™‚ç‚¹ï¼‰

### 5.0 æ¨å¥¨é †ä½

| å„ªå…ˆåº¦ | ãƒ¢ãƒ‡ãƒ« | ç†ç”± |
|--------|--------|------|
| **1ä½** | Gemma 3n E2B | 2GB RAMã§å‹•ä½œã€æ—¥æœ¬èªè‰¯å¥½ã€æœ€æ–°æœ€é©åŒ– |
| **2ä½** | Gemma 2 2B JPN | æ—¥æœ¬èªç‰¹åŒ–ã€å®‰å®šæ€§é«˜ã„ |
| **3ä½** | Qwen 2.5 3B | æ—¥æœ¬èªå„ªç§€ã€ãƒ¢ãƒã‚¤ãƒ«è¨­è¨ˆ |
| **4ä½** | Llama 3.2 1B (é‡å­åŒ–) | æœ€è»½é‡ã€åºƒã„ãƒ‡ãƒã‚¤ã‚¹å¯¾å¿œ |

**StopShortså‘ã‘çµè«–**:
- **æ—¥æœ¬èªãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘**: Gemma 2 2B JPN ã¾ãŸã¯ Gemma 3n ã‚’æ¨å¥¨
- **å¤šè¨€èª/ã‚°ãƒ­ãƒ¼ãƒãƒ«å±•é–‹**: Qwen 2.5 3B ã‚’æ¨å¥¨
- **ãƒ­ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒã‚¤ã‚¹å¯¾å¿œ**: Llama 3.2 1B (é‡å­åŒ–ç‰ˆ) ã‚’æ¨å¥¨

---

## 6. StopShortsã¸ã®æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

### 6.1 å®Ÿè£…æˆ¦ç•¥

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           AIãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. ãƒ‡ãƒã‚¤ã‚¹åˆ¤å®š                             â”‚
â”‚     â”œâ”€ iOS: Apple Intelligenceå¯¾å¿œ?         â”‚
â”‚     â””â”€ Android: Gemini Nanoå¯¾å¿œ?            â”‚
â”‚                                             â”‚
â”‚  2a. ãƒã‚¤ãƒ†ã‚£ãƒ–APIå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹               â”‚
â”‚      â†’ Apple Intelligence / Gemini Nano    â”‚
â”‚                                             â”‚
â”‚  2b. éå¯¾å¿œã ãŒãƒã‚¤ã‚¹ãƒšãƒƒã‚¯ãƒ‡ãƒã‚¤ã‚¹          â”‚
â”‚      â†’ llama.rn + è»½é‡ãƒ¢ãƒ‡ãƒ« (1-2B)        â”‚
â”‚                                             â”‚
â”‚  2c. ãƒ­ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒã‚¤ã‚¹                      â”‚
â”‚      â†’ ã€Œæœ¬ãƒ‡ãƒã‚¤ã‚¹ã§ã¯AIæ©Ÿèƒ½ã‚’             â”‚
â”‚         åˆ©ç”¨ã§ãã¾ã›ã‚“ã€è¡¨ç¤º                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 å„ªå…ˆé †ä½

1. **Phase 1**: Gemini Nano (Android) + Apple Intelligence (iOS)
   - ãƒã‚¤ãƒ†ã‚£ãƒ–APIã‚’å„ªå…ˆä½¿ç”¨
   - æœ€ã‚‚å®‰å®šãƒ»é«˜é€Ÿãƒ»çœé›»åŠ›

2. **Phase 2**: llama.rn ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
   - ãƒã‚¤ãƒ†ã‚£ãƒ–APIéå¯¾å¿œã ãŒãƒã‚¤ã‚¹ãƒšãƒƒã‚¯ãªãƒ‡ãƒã‚¤ã‚¹å‘ã‘
   - å°å‹ãƒ¢ãƒ‡ãƒ« (Gemma 2B, Phi-2ãªã©) ã‚’ä½¿ç”¨

3. **Phase 3**: UI/UXã®æ´—ç·´
   - éå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ã¸ã®é©åˆ‡ãªæ¡ˆå†…
   - ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ»ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### 6.3 å¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ç‡ã®è©¦ç®—

| ã‚«ãƒ†ã‚´ãƒª | iOS | Android | åˆè¨ˆ |
|---------|-----|---------|------|
| ãƒã‚¤ãƒ†ã‚£ãƒ–APIå¯¾å¿œ | 30-40% | 20-30% | 25-35% |
| llama.rnã§è¿½åŠ å¯¾å¿œ | +10% | +15% | +10-15% |
| **åˆè¨ˆå¯¾å¿œç‡** | 40-50% | 35-45% | **35-50%** |

â€» 2024å¹´æœ«æ™‚ç‚¹ã®æ¨å®šã€‚æ–°æ©Ÿç¨®ã®æ™®åŠã«ä¼´ã„å¢—åŠ äºˆå®šã€‚

### 6.4 éå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ã¸ã®å¯¾å¿œ

```typescript
// éå¯¾å¿œæ™‚ã®è¡¨ç¤º
const AIUnavailableScreen = () => (
  <View>
    <Text>AIæ©Ÿèƒ½ã«ã¤ã„ã¦</Text>
    <Text>
      ãŠä½¿ã„ã®ãƒ‡ãƒã‚¤ã‚¹ã§ã¯AIãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚’
      ã”åˆ©ç”¨ã„ãŸã ã‘ã¾ã›ã‚“ã€‚

      ä»¥ä¸‹ã®æ©Ÿèƒ½ã¯å¼•ãç¶šãã”åˆ©ç”¨ã„ãŸã ã‘ã¾ã™ï¼š
      â€¢ ä»‹å…¥æ©Ÿèƒ½ï¼ˆå‘¼å¸ãƒ»ãƒ•ãƒªã‚¯ã‚·ãƒ§ãƒ³ãƒ»ãƒŸãƒ©ãƒ¼ï¼‰
      â€¢ å¿ƒç†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆè¨˜äº‹ãƒ»ã‚¯ã‚¤ã‚ºãƒ»ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆï¼‰
      â€¢ çµ±è¨ˆãƒ»é€²æ—ç¢ºèª
    </Text>
  </View>
);
```

---

## 7. æŠ€è¡“çš„ãƒªã‚¹ã‚¯ã¨å¯¾ç­–

| ãƒªã‚¹ã‚¯ | å½±éŸ¿ | å¯¾ç­– |
|-------|------|------|
| ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ¶ˆè²» | 1-4GB | ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ |
| æ¨è«–æ™‚ã®ãƒ¡ãƒ¢ãƒªä¸è¶³ | ã‚¢ãƒ—ãƒªã‚¯ãƒ©ãƒƒã‚·ãƒ¥ | äº‹å‰ã«ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯ |
| ãƒãƒƒãƒ†ãƒªãƒ¼æ¶ˆè²» | ãƒ¦ãƒ¼ã‚¶ãƒ¼é›¢è„± | ä¼šè©±é•·ã®åˆ¶é™ |
| ä¸­å›½ã§ã®Apple Intelligenceéå¯¾å¿œ | æ©Ÿèƒ½åˆ¶é™ | llama.rnãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ |
| Android ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ | æ©Ÿèƒ½åœæ­¢ | æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ• |

---

## 8. æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

- [ ] Gemma 3n ã¾ãŸã¯ Gemma 2 2B JPN ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ä½œæˆ
- [ ] react-native-executorch ã§ã® Gemma ãƒ¢ãƒ‡ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ
- [ ] llama.rn ã§ã® Qwen 2.5 3B / Llama 3.2 1B ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- [ ] Gemini Nano ML Kit ã®å‹•ä½œæ¤œè¨¼ï¼ˆå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ã§ï¼‰
- [ ] ãƒ‡ãƒã‚¤ã‚¹åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè£…
- [ ] éå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹å‘ã‘UIã®è¨­è¨ˆ
- [ ] æ—¥æœ¬èªä¼šè©±å“è³ªã®è©•ä¾¡ãƒ†ã‚¹ãƒˆ

---

## å‚è€ƒãƒªãƒ³ã‚¯

### Apple
- [Apple Foundation Models (2025)](https://machinelearning.apple.com/research/apple-foundation-models-2025-updates)
- [Core ML ã§ Llama ã‚’å‹•ã‹ã™](https://machinelearning.apple.com/research/core-ml-on-device-llama)
- [Apple Intelligence å¯¾å¿œãƒ‡ãƒã‚¤ã‚¹](https://support.apple.com/en-us/121115)

### Google
- [Gemini Nano ML Kit GenAI APIs](https://android-developers.googleblog.com/2025/05/on-device-gen-ai-apis-ml-kit-gemini-nano.html)
- [Gemini Nano å¯¾å¿œãƒ‡ãƒã‚¤ã‚¹](https://www.androidpolice.com/what-phones-support-gemini-nano/)

### React Native
- [llama.rn GitHub](https://github.com/mybigday/llama.rn)
- [react-native-executorch](https://github.com/software-mansion/react-native-executorch)
- [Expo ãƒ–ãƒ­ã‚°: On-device AI](https://expo.dev/blog/how-to-run-ai-models-with-react-native-executorch)
- [HuggingFace: LLM on Edge](https://huggingface.co/blog/llm-inference-on-edge)

### è»½é‡ãƒ¢ãƒ‡ãƒ« (2025-2026å¹´)
- [Gemma 3n å…¬å¼ç™ºè¡¨](https://developers.googleblog.com/en/introducing-gemma-3n/)
- [Gemma 3n é–‹ç™ºè€…ã‚¬ã‚¤ãƒ‰](https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/)
- [Gemma 2 2B æ—¥æœ¬èªç‰ˆ](https://huggingface.co/google/gemma-2-2b-jpn-it)
- [SmolLM3 å…¬å¼ãƒ–ãƒ­ã‚°](https://huggingface.co/blog/smollm3)
- [Qwen 2.5 å…¬å¼ãƒ–ãƒ­ã‚°](https://qwenlm.github.io/blog/qwen2.5-llm/)
- [Llama 3.2 ãƒ¢ãƒã‚¤ãƒ«æœ€é©åŒ–](https://pytorch.org/blog/unleashing-ai-mobile/)
- [Llama 3.2 é‡å­åŒ–ç‰ˆ](https://www.marktechpost.com/2024/10/24/meta-ai-releases-new-quantized-versions-of-llama-3-2-1b-3b-delivering-up-to-2-4x-increases-in-inference-speed-and-56-reduction-in-model-size/)

### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ»æ¯”è¼ƒ
- [2026å¹´ Top Small Language Models](https://www.datacamp.com/blog/top-small-language-models)
- [ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹SLMæ¯”è¼ƒ (2026)](https://www.bentoml.com/blog/the-best-open-source-small-language-models)
- [æ—¥æœ¬èªLLMæ¯”è¼ƒ (2025)](https://www.siliconflow.com/articles/en/best-open-source-LLM-for-Japanese)
- [ãƒ¢ãƒã‚¤ãƒ«LLMæ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯](https://newsroom.arm.com/news/ai-inference-everywhere-with-new-llama-llms-on-arm)
